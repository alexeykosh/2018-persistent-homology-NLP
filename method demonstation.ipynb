{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Демонстрация метода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем те пакеты, которые будем использовать в работе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# пандас для работы с таблицами\n",
    "import nltk\n",
    "# нлтк для работы с текстами (лемматизация и тд.)\n",
    "import matplotlib.pyplot as plt\n",
    "# матплотлиб для графиком\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# для тф-идф\n",
    "from nltk.corpus import stopwords\n",
    "# английские стоп-слова\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подготовка данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для демонстрации я буду использовать этот [датасет](https://www.kaggle.com/uciml/sms-spam-collection-dataset). \n",
    "\n",
    "Для начала откроем его, посмотрим на структуру данных: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете есть лишние столбцы, которые нам не нужны -- удалим их + переименуем столбцы для удобства пользования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'v1': 'type', 'v2': 'message'}, index=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что с данными все в порядке: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обработка сообщений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from persistent.persistent import Persistent\n",
    "# кастомный класс персистент\n",
    "import numpy as np\n",
    "# нампай для работы с коррдинатами и тд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь используя класс Persistent обработаем наши сообщения для получения persistent diagramms (предварительно их лемматизовав):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.message = data.message.str.lower()\n",
    "\n",
    "data.message = data.message.str.replace('[^\\w\\s]','')\n",
    "# удалим лишние пробелы\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# загрузим токенайзеры и лемматайзер\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "#функция для передачи в пандас\n",
    "\n",
    "data['message_l'] = data.message.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "      <th>message_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, go, to, usf, he, lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey there darling its been 3 weeks now...</td>\n",
       "      <td>[freemsg, hey, there, darling, it, been, 3, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "      <td>[a, per, your, request, melle, melle, oru, min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "      <td>[winner, a, a, valued, network, customer, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 11 months or more u r entitled...</td>\n",
       "      <td>[had, your, mobile, 11, month, or, more, u, r,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message  \\\n",
       "0   ham  go until jurong point crazy available only in ...   \n",
       "1   ham                            ok lar joking wif u oni   \n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3   ham        u dun say so early hor u c already then say   \n",
       "4   ham  nah i dont think he goes to usf he lives aroun...   \n",
       "5  spam  freemsg hey there darling its been 3 weeks now...   \n",
       "6   ham  even my brother is not like to speak with me t...   \n",
       "7   ham  as per your request melle melle oru minnaminun...   \n",
       "8  spam  winner as a valued network customer you have b...   \n",
       "9  spam  had your mobile 11 months or more u r entitled...   \n",
       "\n",
       "                                           message_l  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, dont, think, he, go, to, usf, he, lif...  \n",
       "5  [freemsg, hey, there, darling, it, been, 3, we...  \n",
       "6  [even, my, brother, is, not, like, to, speak, ...  \n",
       "7  [a, per, your, request, melle, melle, oru, min...  \n",
       "8  [winner, a, a, valued, network, customer, you,...  \n",
       "9  [had, your, mobile, 11, month, or, more, u, r,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустим приведение сообщений к виду персистент диаграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_ph = []\n",
    "# массив с текстами\n",
    "\n",
    "for element in data.message_l:\n",
    "    # цикл по лемматизированным и разделенным предложениям\n",
    "    \n",
    "    if element:\n",
    "        # если строка не пустая и содержит слова\n",
    "        a = Persistent(split_sent=element, min_count=1, window=4)\n",
    "        # фигачим её в персистент класс\n",
    "        dgms = a.persistent()\n",
    "        # получаем диаграммы\n",
    "        texts_ph.append(flatten([[p.birth for p in dgms[1]], [p.death for p in dgms[1]]]))\n",
    "        # делаем просто длинный список точек как признаки\n",
    "    else:\n",
    "        # если пустая строка добавляем пустоту\n",
    "        texts_ph.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как это выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>948</th>\n",
       "      <th>949</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>953</th>\n",
       "      <th>954</th>\n",
       "      <th>955</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002164</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.001006</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001585</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>-0.000902</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002987</td>\n",
       "      <td>-0.002463</td>\n",
       "      <td>-0.002047</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.001539</td>\n",
       "      <td>-0.001348</td>\n",
       "      <td>-0.001334</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002165</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002720</td>\n",
       "      <td>-0.002165</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.002548</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>-0.001435</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>-0.001141</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.000902</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.003027</td>\n",
       "      <td>-0.002340</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>-0.000961</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.003172</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.003165</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>-0.001818</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>-0.001359</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.001362</td>\n",
       "      <td>-0.001280</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 958 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.002164 -0.001904 -0.001666 -0.001189 -0.001121 -0.001085 -0.001042   \n",
       "1 -0.001585 -0.001416 -0.001129 -0.001074 -0.000981 -0.000902 -0.000720   \n",
       "2 -0.002987 -0.002463 -0.002047 -0.001709 -0.001539 -0.001348 -0.001334   \n",
       "3 -0.002165 -0.001904 -0.001666 -0.001426 -0.001292 -0.001278 -0.001242   \n",
       "4 -0.002720 -0.002165 -0.002008 -0.001906 -0.001329 -0.001278 -0.001169   \n",
       "5 -0.002548 -0.002464 -0.001435 -0.001343 -0.001182 -0.001141 -0.001094   \n",
       "6 -0.003027 -0.002340 -0.001689 -0.001426 -0.001065 -0.001038 -0.001010   \n",
       "7 -0.003172 -0.002161 -0.001294 -0.001159 -0.001085 -0.001053 -0.000958   \n",
       "8 -0.003165 -0.002644 -0.002050 -0.001818 -0.001714 -0.001564 -0.001359   \n",
       "9 -0.002278 -0.001905 -0.001885 -0.001661 -0.001536 -0.001536 -0.001362   \n",
       "\n",
       "        7         8         9   ...   948  949  950  951  952  953  954  955  \\\n",
       "0 -0.001006 -0.000904 -0.000898 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1 -0.000480 -0.000112  0.000048 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2 -0.001328 -0.001078 -0.001045 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3 -0.001009 -0.001000 -0.000741 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4 -0.001038 -0.000927 -0.000425 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "5 -0.001041 -0.000907 -0.000902 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "6 -0.000961 -0.000927 -0.000811 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "7 -0.000936 -0.000925 -0.000900 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "8 -0.001356 -0.001309 -0.001304 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "9 -0.001280 -0.001184 -0.001183 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   956  957  \n",
       "0  NaN  NaN  \n",
       "1  NaN  NaN  \n",
       "2  NaN  NaN  \n",
       "3  NaN  NaN  \n",
       "4  NaN  NaN  \n",
       "5  NaN  NaN  \n",
       "6  NaN  NaN  \n",
       "7  NaN  NaN  \n",
       "8  NaN  NaN  \n",
       "9  NaN  NaN  \n",
       "\n",
       "[10 rows x 958 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ph_df = pd.DataFrame(texts_ph)\n",
    "text_ph_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку координаты получаются разной длины, заполним NaN-ы нулями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ph_df = text_ph_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ph_df.to_csv('X_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y).to_csv('y_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# логистическая регрессия\n",
    "from sklearn.model_selection import train_test_split\n",
    "# разбиение на трейн и тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам надо сделать X и у: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_ph_df\n",
    "# Матрица -- датафрейм с координатами\n",
    "y = pd.factorize(data.type)[0]\n",
    "# заменим слова бинарными символами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем самый простой классификатор -- логистическую регрессию: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(verbose=True)\n",
    "# аргумент verbose -- чтобы смотреть на процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень топорно разобъем признаки на трейн и тест датасеты в отношении 70/30: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "# разбили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как разбили:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 1300)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все ок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафитим модель: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты:\n",
    "\n",
    "* На теренеровочной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86897435897435893"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* На тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85885167464114831"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тренеровчной и тестовой выборке различаются не сильно, значит оверфита нет. Никаких фокусов и никакой магии, все работает."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
